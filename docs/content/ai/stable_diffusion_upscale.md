# 人工智能/Stable Diffusion 图像超分辨率

## 为什么我们需要图像超分辨率

Stable Diffusion v1 的默认图像尺寸为 512×512 像素. 以今天的标准来看, 这个分辨率相当低. 以 iPhone 12 为例, 它的相机拍摄出1200 万像素的图像, 即 4032×3024 像素, 而其显示屏的分辨率为 2532×1170 像素, 因此未经缩放的 Stable Diffusion 图像需要进行放大, 否则会显得质量较低.

更加复杂的情况是, Stable Diffusion 生成的复杂场景通常不够清晰, 细节常常受限. 如果我们让 Stable Diffusion 生成大于 512x512 像素的图像, 又会严重影响图像生成速度并且消耗更多的内存和显存.

## 传统图像放大算法的缺陷

虽然可以使用传统的图像放大算法, 但结果可能不如预期.

传统的图像尺寸调整算法, 例如最近邻插值和 Lanczos 插值, 它们仅依赖原始图像像素值进行数学运算来扩展画面并填充新像素. 然而, 如果图像本身受损或畸变, 这些算法无法准确填充丢失的信息. 使用传统算法可能导致图像失真, 模糊或出现伪像, 而高质量的图像放大通常需要更复杂的方法, 例如神经网络图像放大器, 它们可以通过学习图像的特征来更好地保留细节和纹理, 以获得更高质量的结果.

## 基于人工智能的图像超分辨率是如何工作的

相比之下, 基于人工智能的图像超分辨率是通过大量数据训练的模型. 首先, 优质图像被人工损坏以模拟真实世界的降质. 然后, 将这些降质图像缩小到较小的尺寸. 接着, 通过训练神经网络模型来恢复原始图像. 大量的先验知识被嵌入到模型中. 它能够填充丢失的信息. 这就好像人们不需要详细研究一个人的面部特征来记住它. 我们主要关注一些关键特征.

## 如何使用图像超分辨率

我们将研究如何使用 Stable Diffusion WebUI 进行图像放大.

0. 点击 "Extras" 选项卡(我知道名称令人困惑), 然后选择 "Single Image".
0. 上传您想要放大的图像到 "Source".
0. 设置放大倍数 (Scale by) 或设置目标像素值 (Scale to).
0. Upscale 选择 R-ESRGAN 4x+, 这是适用于大多数图像的 AI 放大器.
0. 点击 "Generate" 以开始放大处理.
0. 处理完成后, 放大后的图像将出现在右侧的输出窗口. 右键单击图像以保存.

## 一些选项

Stable Diffusion WebUI 目前内置了一些图像超分辨率模型, 我将列举它们的主要使用场景.

- LDSR: 潜在扩散超分辨率 (LDSR) 放大器最初是与 Stable Diffusion 1.4 一起发布的. 它是一个经过训练的潜在扩散模型, 用于执行放大任务. 尽管质量卓越, 但速度非常慢. 我不建议使用它.
- ESRGAN 4x: 增强型超分辨率生成对抗网络 (ESRGAN) 是一个放大网络, 曾获得 2018 年感知图像恢复和处理挑战赛的胜利. 它是对先前的 SRGAN 模型的改进. 它倾向于保留细节, 并生成清晰而锐利的图像.
- R-ESRGAN 4x: R-ESRGAN 是对 ESRGAN 的改进, 可以恢复各种真实世界的图像. 它模拟了来自相机镜头和数字压缩的各种程度的失真. 与 ESRGAN 相比, 它倾向于产生更平滑的图像. R-ESRGAN 在处理真实照片图像时表现最佳.
- R-ESRGAN 4x+ Anime6B: 一种基于超分辨率技术的图像增强算法, 主要用于提高动漫图像的质量和清晰度. 它基于 R-ESRGAN 4x+ 算法, 并使用了 Anime6B 数据集进行训练. Anime6B 数据集是一个专门用于动漫图像处理的数据集, 其中包含了大量不同风格, 不同质量的动漫图像, 使得算法可以适应不同类型的动漫图像.
- ScuNET: 对于大多数图像来说太模糊了.
- ScuNET PSNR: ScuNET PSNR 可能是一种专注于提高峰值信噪比 (PSNR) 的超分辨率方法, 用于生成高质量的图像.
- SwinIR_4x: SwinIR 是一种基于 Swin Transformer 的图像超分辨率方法, 可以将图像放大 4 倍. 它使用了最新的 Transformer 架构, 以实现更精确的图像放大. 但需要较高的显存.

## 参考

- [1] [How to use AI image upscaler to improve details, Andrew](https://stable-diffusion-art.com/ai-upscaler/)
